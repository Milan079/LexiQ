{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11814560,"sourceType":"datasetVersion","datasetId":7420676}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q \\\n    transformers \\\n    peft \\\n    huggingface_hub \\\n    accelerate \\\n    bitsandbytes \\\n    sentence-transformers \\\n    langchain \\\n    langchain-community \\\n    PyPDF2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:58:58.196308Z","iopub.execute_input":"2025-05-16T17:58:58.196859Z","iopub.status.idle":"2025-05-16T17:59:06.822991Z","shell.execute_reply.started":"2025-05-16T17:58:58.196587Z","shell.execute_reply":"2025-05-16T17:59:06.821651Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\nimport torch\nimport gc\n\ngc.collect()\ntorch.cuda.empty_cache()\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import PeftModel\nfrom huggingface_hub import login\nfrom PyPDF2 import PdfReader\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.docstore.document import Document\n\nlogin(token=\"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\")\n\ndef load_model_and_tokenizer():\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_compute_dtype=torch.float16,\n    )\n\n    tokenizer = AutoTokenizer.from_pretrained(\n        \"NishKook/legal-qa-lora\", use_auth_token=True\n    )\n\n    base_model = AutoModelForCausalLM.from_pretrained(\n        \"mistralai/Mistral-7B-Instruct-v0.2\",\n        device_map=\"auto\",\n        torch_dtype=torch.float16,\n        quantization_config=bnb_config,\n        use_auth_token=True,\n        max_memory={0: \"13GiB\", \"cpu\": \"12GiB\"} \n    )\n\n    model = PeftModel.from_pretrained(\n        base_model,\n        \"NishKook/legal-qa-lora\",\n        device_map=\"auto\",\n        torch_dtype=torch.float16,\n        use_auth_token=True\n    )\n\n    model.eval()\n    return model, tokenizer\n\nmodel, tokenizer = load_model_and_tokenizer()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef extract_text_from_pdf(pdf_path):\n    reader = PdfReader(pdf_path)\n    return \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n\ndef build_vector_index(text):\n    splitter = RecursiveCharacterTextSplitter(chunk_size=384, chunk_overlap=32)\n    docs = [Document(page_content=chunk) for chunk in splitter.split_text(text)]\n    return FAISS.from_documents(docs, HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n\ndef get_context(question, vectordb, k=7):\n    top_docs = vectordb.similarity_search(question, k=k)\n    return \"\\n\".join([doc.page_content for doc in top_docs])\n\ndef generate_answer(question, context):\n    prompt = f\"### Question:\\n{question}\\n\\n### Context:\\n{context}\\n\\n### Answer:\\n\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=256,\n            do_sample=False\n        )\n    return tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n\ndef answer_from_pdf(pdf_path, question):\n    print(\"Extracting text from PDF...\")\n    text = extract_text_from_pdf(pdf_path)\n\n    print(\"Building FAISS index...\")\n    vectordb = build_vector_index(text)\n\n    print(f\"Question: {question}\")\n    context = get_context(question, vectordb)\n\n    print(\"\\n Retrieved Context Snippet:\\n\")\n    print(context[:500], \"...\\n\")\n\n    print(\"Generating answer...\\n\")\n    return generate_answer(question, context)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:08:07.136708Z","iopub.execute_input":"2025-05-16T18:08:07.137077Z","iopub.status.idle":"2025-05-16T18:08:34.081523Z","shell.execute_reply.started":"2025-05-16T18:08:07.137053Z","shell.execute_reply":"2025-05-16T18:08:34.080778Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfeeab57cf2b4939be5647199916db46"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"pdf_path = \"/kaggle/input/case-file/Case File.pdf\"\nquestion = \"What did the Dobbs Court decide about Roe v. Wade?\"\nanswer = answer_from_pdf(pdf_path, question)\nprint(\"\\n Final Answer:\\n\", answer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:08:34.082802Z","iopub.execute_input":"2025-05-16T18:08:34.083092Z","iopub.status.idle":"2025-05-16T18:08:46.550430Z","shell.execute_reply.started":"2025-05-16T18:08:34.083065Z","shell.execute_reply":"2025-05-16T18:08:46.549604Z"}},"outputs":[{"name":"stdout","text":"Extracting text from PDF...\nBuilding FAISS index...\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Question: What did the Dobbs Court decide about Roe v. Wade?\n\n Retrieved Context Snippet:\n\nAPPENDIX \nThis Appendix analyzes in full each of the 28 cases the\nmajority says support today’ s decision to overrule Roe v. \nWade , 410 U. S. 113 (1973), and Planned Parenthood of \nSoutheastern Pa. v. Casey , 505 U. S. 833 (1992).  As ex-\nplained herein, the Court in each case relied on traditional \nstare decisis  factors in overruling.\n6 DOBBS v. JACKSON WOMEN’S HEALTH ORGANIZATION \nOpinion of the Court \nopinion was based, does not compel unending adherence to \nRoe’s abuse of judicial authorit ...\n\nGenerating answer...\n\n\n Final Answer:\n The Dobbs Court decided to overrule Roe v. Wade and Planned Parenthood of Southeastern Pennsylvania v. Casey. The Court held that the Constitution does not confer a right to abortion on demand, and that the power to regulate abortion rests with the States.\n","output_type":"stream"}],"execution_count":11}]}