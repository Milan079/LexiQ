{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11636169,"sourceType":"datasetVersion","datasetId":7300980}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U bitsandbytes datasets accelerate peft transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T14:23:12.008897Z","iopub.execute_input":"2025-05-07T14:23:12.009497Z","iopub.status.idle":"2025-05-07T14:23:15.689905Z","shell.execute_reply.started":"2025-05-07T14:23:12.009470Z","shell.execute_reply":"2025-05-07T14:23:15.688916Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\nos.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n\nimport torch\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForLanguageModeling,\n)\nfrom peft import LoraConfig, get_peft_model, TaskType\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T14:23:15.691438Z","iopub.execute_input":"2025-05-07T14:23:15.691683Z","iopub.status.idle":"2025-05-07T14:23:26.417370Z","shell.execute_reply.started":"2025-05-07T14:23:15.691661Z","shell.execute_reply":"2025-05-07T14:23:26.416754Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746627802.673266     239 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746627802.681320     239 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"cuad = load_dataset(\"json\", data_files=\"/kaggle/input/cuadv1/CUADv1.json\")[\"train\"]\nsara = load_dataset(\"jhu-clsp/SARA\", split=\"train\")\n\ndef preprocess_cuad(dataset):\n    out = []\n    for item in dataset:\n        for entry in item[\"data\"]:\n            for p in entry[\"paragraphs\"]:\n                ctx = p[\"context\"]\n                for qa in p[\"qas\"]:\n                    if qa[\"answers\"]:\n                        out.append({\n                            \"question\": qa[\"question\"],\n                            \"context\": ctx,\n                            \"answer\": qa[\"answers\"][0][\"text\"]\n                        })\n    return out\n\ncuad_data = preprocess_cuad(cuad)\nsara_data = [\n    {\"question\": x[\"question\"], \"context\": x[\"text\"], \"answer\": x[\"answer\"]}\n    for x in sara\n]\n\nall_examples = cuad_data + sara_data\ndataset = Dataset.from_list(all_examples)\nprint(f\"Total examples: {len(dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T14:23:26.418458Z","iopub.execute_input":"2025-05-07T14:23:26.419067Z","iopub.status.idle":"2025-05-07T14:23:33.167550Z","shell.execute_reply.started":"2025-05-07T14:23:26.419046Z","shell.execute_reply":"2025-05-07T14:23:33.166776Z"}},"outputs":[{"name":"stdout","text":"Total examples: 6958\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice_idx = device.index if device.type == \"cuda\" else None\n\nmodel_id = \"NousResearch/Hermes-2-Pro-Mistral-7B\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    device_map={\"\": device_idx},   # ← all layers → cuda:0\n)\n\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM,\n)\nmodel = get_peft_model(model, lora_config).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T14:23:33.168413Z","iopub.execute_input":"2025-05-07T14:23:33.168686Z","iopub.status.idle":"2025-05-07T14:24:13.454798Z","shell.execute_reply.started":"2025-05-07T14:23:33.168661Z","shell.execute_reply":"2025-05-07T14:24:13.454243Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0131395e752e4af0839dff8a9c49bcb1"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def format_example(ex):\n    prompt = (\n        f\"### Question:\\n{ex['question']}\\n\"\n        f\"### Context:\\n{ex['context']}\\n\"\n        \"### Answer:\\n\"\n    )\n    full = prompt + ex[\"answer\"]\n    tok = tokenizer(full, truncation=True, max_length=512, padding=\"max_length\")\n    input_ids = tok[\"input_ids\"]\n    attn_mask = tok[\"attention_mask\"]\n\n    p_tok = tokenizer(prompt, truncation=True, max_length=len(input_ids))[\"input_ids\"]\n    p_len = len(p_tok)\n\n    labels = input_ids.copy()\n    for i in range(p_len):\n        labels[i] = -100\n\n    return {\"input_ids\": input_ids, \"attention_mask\": attn_mask, \"labels\": labels}\n\ntokenized = dataset.map(format_example, remove_columns=dataset.column_names)\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T14:24:13.456077Z","iopub.execute_input":"2025-05-07T14:24:13.456347Z","iopub.status.idle":"2025-05-07T14:34:39.244180Z","shell.execute_reply.started":"2025-05-07T14:24:13.456321Z","shell.execute_reply":"2025-05-07T14:34:39.243385Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6958 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e70218d8f8fa4820a6f709035f070321"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./legal_qa_lora\",\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=4,\n    learning_rate=2e-4,\n    num_train_epochs=2,\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    fp16=True,\n    report_to=\"none\",\n)\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T14:34:39.245100Z","iopub.execute_input":"2025-05-07T14:34:39.245405Z","iopub.status.idle":"2025-05-07T17:12:06.858381Z","shell.execute_reply.started":"2025-05-07T14:34:39.245376Z","shell.execute_reply":"2025-05-07T17:12:06.857717Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_239/3101751527.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='870' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [870/870 2:37:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.793500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.667200</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.608500</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.622700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.555000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.569200</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.543300</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.513200</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.548300</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.516200</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.519100</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.482600</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.504800</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.511400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.468900</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.462600</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.451200</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.453600</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.433300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.430300</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.428300</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.409000</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.407100</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.415400</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.368400</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.400800</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.373200</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.366700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.345900</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.361200</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.331700</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.312700</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.338100</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.315000</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.300300</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.315500</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.307900</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.292200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.324100</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.304500</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.274800</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.272600</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.260200</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.270600</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.283200</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.253200</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.240800</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.245600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.214400</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.222600</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.255200</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.226500</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.238600</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.227900</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.234200</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.199500</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.196300</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.191300</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.227300</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.189100</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.191500</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.182200</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.168300</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.176900</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.165700</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.181000</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.157700</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.153000</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.201500</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.165600</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.156000</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.174300</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.148400</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.172900</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.152000</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.131000</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.156400</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.162300</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.172800</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.148600</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.145900</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.122700</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.127900</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.141900</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.165000</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.145800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=870, training_loss=0.3099334276955703, metrics={'train_runtime': 9447.1943, 'train_samples_per_second': 1.473, 'train_steps_per_second': 0.092, 'total_flos': 3.042773538428682e+17, 'train_loss': 0.3099334276955703, 'epoch': 2.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"model.save_pretrained(\"./final_legal_lora\")\ntokenizer.save_pretrained(\"./final_legal_lora\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T17:34:33.292062Z","iopub.execute_input":"2025-05-07T17:34:33.292741Z","iopub.status.idle":"2025-05-07T17:34:33.614238Z","shell.execute_reply.started":"2025-05-07T17:34:33.292713Z","shell.execute_reply":"2025-05-07T17:34:33.613623Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"('./final_legal_lora/tokenizer_config.json',\n './final_legal_lora/special_tokens_map.json',\n './final_legal_lora/tokenizer.model',\n './final_legal_lora/added_tokens.json',\n './final_legal_lora/tokenizer.json')"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=\"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\")\n\ntokenizer.push_to_hub(\"NishKook/legal-qa-lora\", use_auth_token=True)\nmodel.push_to_hub(\"NishKook/legal-qa-lora\", use_auth_token=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T17:35:18.663529Z","iopub.execute_input":"2025-05-07T17:35:18.664273Z","iopub.status.idle":"2025-05-07T17:35:22.862594Z","shell.execute_reply.started":"2025-05-07T17:35:18.664249Z","shell.execute_reply":"2025-05-07T17:35:22.861730Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4f91ffa90b9459fa291fd27c890325c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1f89aee64db431aa9397f8258bdecd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17797e1276cf4c4abeaf9542a3daa789"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/NishKook/legal-qa-lora/commit/9a1e9dbb5660575cbc49cd84abaae9b14421f5cd', commit_message='Upload model', commit_description='', oid='9a1e9dbb5660575cbc49cd84abaae9b14421f5cd', pr_url=None, repo_url=RepoUrl('https://huggingface.co/NishKook/legal-qa-lora', endpoint='https://huggingface.co', repo_type='model', repo_id='NishKook/legal-qa-lora'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import torch\nfrom huggingface_hub import login\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import PeftModel\n\ntorch.cuda.empty_cache()\n\nlogin(token=\"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\")\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice_idx = device.index if device.type == \"cuda\" else None\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\ntokenizer_inf = AutoTokenizer.from_pretrained(\n    \"NishKook/legal-qa-lora\",\n    use_auth_token=True\n)\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mistral-7B-Instruct-v0.2\",\n    quantization_config=bnb_config,\n    device_map={\"\": device_idx},\n    torch_dtype=torch.float16,\n    use_auth_token=True\n)\n\nmodel_inf = PeftModel.from_pretrained(\n    base_model,\n    \"NishKook/legal-qa-lora\",\n    device_map={\"\": device_idx},\n    torch_dtype=torch.float16,\n    use_auth_token=True\n).to(device)\nmodel_inf.eval()\n\ndef answer(question: str, context: str) -> str:\n    prompt = (\n        f\"### Question:\\n{question}\\n\\n\"\n        f\"### Context:\\n{context}\\n\\n\"\n        \"### Answer:\\n\"\n    )\n    inputs = tokenizer_inf(prompt, return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        output_ids = model_inf.generate(\n            **inputs,\n            max_new_tokens=256,  \n            do_sample=False\n        )\n    # strip off the prompt tokens\n    return tokenizer_inf.decode(\n        output_ids[0][inputs.input_ids.shape[1]:],\n        skip_special_tokens=True\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:05:32.320496Z","iopub.execute_input":"2025-05-13T07:05:32.321234Z","iopub.status.idle":"2025-05-13T07:06:08.256460Z","shell.execute_reply.started":"2025-05-13T07:05:32.321202Z","shell.execute_reply":"2025-05-13T07:06:08.255898Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b4166693594513b4d0d992e927b975"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"question = \"What are the four elements of negligence?\"\ncontext  = (\n    \"Under tort law, negligence requires four elements: \"\n    \"a duty of care, a breach of that duty, \"\n    \"causation linking the breach to harm, and actual damages suffered by the plaintiff.\"\n)\n\nprint(\"Question:\", question)\nprint(\"Answer:  \", answer(question, context))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:06:45.739393Z","iopub.execute_input":"2025-05-13T07:06:45.739731Z","iopub.status.idle":"2025-05-13T07:06:52.385230Z","shell.execute_reply.started":"2025-05-13T07:06:45.739709Z","shell.execute_reply":"2025-05-13T07:06:52.384494Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Question: What are the four elements of negligence?\nAnswer:   Yes, that is correct. The four elements of a negligence claim under tort law are: (1) a duty of care owed by the defendant to the plaintiff, (2) a breach of that duty by the defendant, (3) causation linking the defendant's breach to harm suffered by the plaintiff, and (4) actual damages or harm suffered by the plaintiff.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"question = \"When can a contract be considered voidable?\"\ncontext  = (\n    \"A contract may be voidable if one party lacked capacity to contract, \"\n    \"if there was misrepresentation or duress, or if undue influence was exercised.\"\n)\n\nprint(\"Question:\", question)\nprint(\"Answer:  \", answer(question, context))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:06:52.386343Z","iopub.execute_input":"2025-05-13T07:06:52.386852Z","iopub.status.idle":"2025-05-13T07:07:10.087077Z","shell.execute_reply.started":"2025-05-13T07:06:52.386830Z","shell.execute_reply":"2025-05-13T07:07:10.086242Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Question: When can a contract be considered voidable?\nAnswer:   A contract may be considered voidable if:\n\n1. One party lacked capacity to contract at the time the contract was entered into. For example, a person who is mentally incompetent or a minor cannot enter into a contract.\n\n2. There was misrepresentation or fraud. Misrepresentation occurs when one party makes a false statement of fact or fails to disclose a material fact, which induces the other party to enter into the contract. Fraud occurs when one party intentionally deceives another party by knowingly making a false statement or concealing a material fact.\n\n3. There was duress. Duress occurs when one party is coerced into entering into a contract by the threat of harm or the infliction of harm upon that party or a third party.\n\n4. Undue influence was exercised. Undue influence occurs when one party takes advantage of the vulnerability of another party to exert pressure on that party to enter into a contract. This can include physical or emotional manipulation, or the use of a position of power or trust to influence the other party.\n\nIn each of these cases, the contract may be voidable, meaning that it may be unenforceable or un\n","output_type":"stream"}],"execution_count":7}]}